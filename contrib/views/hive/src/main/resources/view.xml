<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<view>
    <name>HIVE</name>
    <label>Hive</label>
    <version>0.1.0</version>

    <min-ambari-version>1.7.*</min-ambari-version>

    <!-- HDFS Configs -->
    <parameter>
        <name>webhdfs.url</name>
        <description>Enter the WebHDFS FileSystem URI. Typically this is the dfs.namenode.http-address property in the hdfs-site.xml configuration. URL must be accessible from Ambari Server.</description>
        <label>WebHDFS FileSystem URI</label>
        <placeholder>webhdfs://namenode:50070</placeholder>
        <required>true</required>
    </parameter>

    <parameter>
        <name>webhdfs.username</name>
        <description>doAs for proxy user for HDFS. By default, uses the currently logged-in Ambari user.</description>
        <label>WebHDFS Username</label>
        <required>false</required>
    </parameter>

    <parameter>
        <name>webhdfs.auth</name>
        <description>Semicolon-separated authentication configs.</description>
        <label>WebHDFS Authentication</label>
        <placeholder>auth=SIMPLE</placeholder>
        <default-value>auth=SIMPLE</default-value>
        <required>false</required>
    </parameter>

    <!-- General Configs -->

    <parameter>
        <name>dataworker.username</name>
        <description>The dataworker username. By default, users the currently logged-in Ambari user.</description>
        <label>Dataworker Username</label>
        <required>false</required>
    </parameter>

    <parameter>
        <name>scripts.dir</name>
        <description>HDFS directory path to store Hive scripts.</description>
        <label>Scripts HDFS Directory</label>
        <placeholder>/user/${username}/hive/scripts</placeholder>
        <default-value>/user/${username}/hive/scripts</default-value>
        <required>true</required>
    </parameter>

    <parameter>
        <name>jobs.dir</name>
        <description>HDFS directory path to store Hive job status.</description>
        <label>Jobs HDFS Directory</label>
        <placeholder>/user/${username}/hive/jobs</placeholder>
        <default-value>/user/${username}/hive/jobs</default-value>
        <required>true</required>
    </parameter>

    <parameter>
        <name>hive.host</name>
        <description>Enter the HiveServer2 host. Host must be accessible from Ambari Server.</description>
        <label>HiveServer2 Host</label>
        <placeholder>127.0.0.1</placeholder>
        <required>true</required>
    </parameter>

    <parameter>
        <name>hive.port</name>
        <description>HiveServer2 Thrift port (example: 10000).</description>
        <label>HiveServer2 Thrift port</label>
        <placeholder>10000</placeholder>
        <default-value>10000</default-value>
        <required>true</required>
    </parameter>

    <parameter>
        <name>hive.auth</name>
        <description>Semicolon-separated authentication configs.</description>
        <label>Hive Authentication</label>
        <placeholder>auth=NONE</placeholder>
        <default-value>auth=NONE</default-value>
        <required>false</required>
    </parameter>

    <parameter>
        <name>yarn.ats.url</name>
        <description>The URL to the YARN Application Timeline Server, used to provide Jobs information, typically, this is the yarn.timeline-service.webapp.address property in the yarn-site.xml configuration.</description>
        <placeholder>http://yarn.ats.address:8188</placeholder>
        <required>true</required>
    </parameter>

    <resource>
        <name>savedQuery</name>
        <plural-name>savedQueries</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.savedQueries.SavedQuery</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.savedQueries.SavedQueryResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.savedQueries.SavedQueryService</service-class>
    </resource>

    <resource>
        <name>fileResource</name>
        <plural-name>fileResources</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.resources.FileResourceItem</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.resources.FileResourceResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.resources.FileResourceService</service-class>
    </resource>

    <resource>
        <name>udf</name>
        <plural-name>udfs</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.udfs.UDF</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.udfs.UDFResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.udfs.UDFService</service-class>
    </resource>

    <resource>
        <name>job</name>
        <plural-name>jobs</plural-name>
        <id-property>id</id-property>
        <resource-class>org.apache.ambari.view.hive.resources.jobs.viewJobs.JobImpl</resource-class>
        <provider-class>org.apache.ambari.view.hive.resources.jobs.JobResourceProvider</provider-class>
        <service-class>org.apache.ambari.view.hive.resources.jobs.JobService</service-class>
    </resource>

    <resource>
        <name>file</name>
        <service-class>org.apache.ambari.view.hive.resources.files.FileService</service-class>
    </resource>

    <resource>
        <name>ddl</name>
        <service-class>org.apache.ambari.view.hive.resources.browser.HiveBrowserService</service-class>
    </resource>

    <resource>
        <name>hive</name>
        <service-class>org.apache.ambari.view.hive.HelpService</service-class>
    </resource>

    <persistence>
        <entity>
            <class>org.apache.ambari.view.hive.persistence.DataStoreStorage$SmokeTestEntity</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.jobs.viewJobs.JobImpl</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.jobs.StoredOperationHandle</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.savedQueries.SavedQuery</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.udfs.UDF</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.resources.resources.FileResourceItem</class>
            <id-property>id</id-property>
        </entity>
        <entity>
            <class>org.apache.ambari.view.hive.TestBean</class>
            <id-property>id</id-property>
        </entity>
    </persistence>
</view>
